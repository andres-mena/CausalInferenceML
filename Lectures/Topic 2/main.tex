\documentclass[xcolor=svgnames,t]{beamer} 
\usepackage[utf8]{inputenc}
\usepackage{booktabs, comment}
\usepackage{graphicx}  % Add graphicx package
\usepackage[absolute, overlay]{textpos} 
\usepackage{pgfpages}
\usepackage[font=footnotesize]{caption}
\useoutertheme{infolines} 
\usepackage{xcolor}
% \usepackage{cite}  % REMOVE this line because it conflicts with natbib
\usepackage{colortbl}
\definecolor{brownbrown}{RGB}{8, 8, 9}
\usepackage[round, sort, authoryear]{natbib}  % Use only natbib for citation management
\definecolor{brownred}{RGB}{198, 198, 198}

\setbeamercolor{title in head/foot}{bg=brownred, fg=brownbrown}
\setbeamercolor{author in head/foot}{bg=myuniversity}
\setbeamertemplate{page number in head/foot}{}

\usepackage{amsmath}
\usepackage[makeroom]{cancel}

\newtheorem{equi}{} %Creates a grey box when equi is called
\setbeamertemplate{navigation symbols}{} 
\usepackage{textpos}

\usepackage{tikz}

\usetheme{Madrid}
\definecolor{myuniversity}{RGB}{48, 67, 180}
\usecolortheme[named=myuniversity]{structure}
\usepackage{tikz}


\usepackage{colortbl} 
\newcommand{\myitem}{\item[$\circ$]}
\newcommand{\witem}{\item[\textcolor{white}{$\bullet$}]}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\AtBeginSection[]{
\begin{frame}
\frametitle{Content}
\tableofcontents[currentsection]
\end{frame}
}

\title[Randomized Experiment]{Randomized Experiment}
\subtitle{}
%\titlegraphic{\includegraphics[height=1cm]{brown-logo.png}}  % This line is commented out to remove the logo
\author[CIML ]{Causal Inference using Machine Learning\\ Master in Economics, UNT}
\institute[]{Andres Mena}
\date{Spring 2024}

\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}

\begin{document}
\begin{frame}
\maketitle
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\logo{\includegraphics[height=0.5cm]{brown-arms.png}}  % This line is commented out to remove the logo
%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
    \frametitle{Table of Contents}
    \tableofcontents
\end{frame}

\section{Origins of Randomized Experiments}
\begin{frame}{The first RCT}
    \begin{block}{}
        "Let us divide them in halves, let us cast lots, that one half of them may fall to my share, and the other to yours; I will cure them without bloodletting and sensible evacuation; but do you do as ye know [...] we shall see how many Funerals both of us shall have."\\
        – Jan Baptist van Helmont, 1624
    \end{block}
    \begin{itemize}[<+->]
        \item \textbf{Van Helmont (17th century)}: Suggested dividing patients by lot to compare treatments, an early hint of experimental control.
        \item \textbf{Peirce (1885)}: Used random sequencing in psychology to prevent bias from expectations, anticipating randomization principles.
        \item \textbf{Gossett and Fisher (1920s)}: Gossett mentioned random plot placement; Fisher formalized randomization as essential for causal inference.
    \end{itemize}
\end{frame}
% Frame for Neyman (1923)
\begin{frame}{ \cite{neyman1923}}
    \begin{itemize}[<+->]
        \item Introduced the concept of potential outcomes to define causal effects.
        \item Applied potential outcomes specifically in the context of randomized experiments.
        \item Developed notation for potential yields in agricultural experiments, allowing estimation across different treatment groups.
        \item Emphasized the role of assignment mechanisms in calculating causal effects.
        \item Proposed an estimator for the Variance of the Average Treatment Effect (ATE) in randomized experiments.
    \end{itemize}
\end{frame}

% Frame for Fisher (1935)
\begin{frame}{\cite{fisher1935}}
    \begin{itemize}[<+->]
        \item Established randomization as the fundamental basis for valid causal inference.
        \item Introduced the concept of statistical significance and p-values within the framework of randomized experiments.
        \item Developed randomization techniques like randomized blocks, which became standard in experimental design.
        \item Emphasized the need for physical randomization to eliminate confounding variables.
        \item Proposed methods for testing hypotheses in a controlled experimental setup.
    \end{itemize}
\end{frame}

% Contrast Frame
\begin{frame}{Comparison: Neyman vs. Fisher}
    \begin{itemize}[<+->]
        \item \textbf{Neyman (1923)} focused on potential outcomes to estimate causal effects, but Fisher (1935) emphasized randomization as the basis for inference.
        \item Neyman treated randomization as a theoretical basis for probabilistic analysis, while Fisher emphasized physical randomization as essential for credible causal inference, making it a core requirement of experimental validity.
        \item Fisher introduced significance testing and p-values for general hypothesis, while Neyman was more concerned with unbiased estimation of ATE.
      
        \item Together, they laid the groundwork for randomized experiments and causal inference.
    \end{itemize}
\end{frame}
\section{Classification of Assignment Mechanisms}

\begin{frame}{Definition of Assignment Vector \( D \)}
    \begin{itemize}[<+->]
        \item \textbf{Assignment Vector}: A vector representing the treatment assignment for each unit in a study.
        \item For \( N \) units, \( D \) is an \( N \)-vector where \( D_i = d \) if unit \( i \) receives the treatment $d$.
        \item For two treatment groups, \( D \) is a binary vector with \( 2^N \) possible values.
    \end{itemize}
    
   
\end{frame}


\begin{frame}{Assignment Mechanism}
    \textbf{Assignment Mechanism:} Given a population of \( N \) units, the assignment mechanism is a row-exchangeable function, denoted as \( \Pr(D | X, Y(0), Y(1)) \), which takes values in the interval \([0, 1]\) and satisfies:
    
    \[
    \sum_{D \in \{0,1\}^N} \Pr(D | X, Y(0), Y(1)) = 1
    \]

    for all possible values of \( X \) (covariates), \( Y(0) \), and \( Y(1) \) (potential outcomes). (Row-exchangeability implies that the order of units within vectors or matrices is irrelevant to the function \( \Pr(\cdot) \).)
   
\end{frame}

\begin{frame}{Example: Assignment Mechanism with Two Units}
    Define the \textbf{treatment effect} for unit \( i \) as:
    \(
    \tau_i = Y_i(1) - Y_i(0)
    \)

    \[
    \Pr(D | X, Y(0), Y(1)) = 
    \begin{cases} 
      1 & \text{if } \tau_2 > \tau_1 \text{ and } D = \begin{bmatrix} 0 \\ 1 \end{bmatrix} \\[10pt]
      1 & \text{if } \tau_2 < \tau_1 \text{ and } D = \begin{bmatrix} 1 \\ 0 \end{bmatrix} \\[10pt]
      \frac{1}{2} & \text{if } \tau_2 = \tau_1 \text{ and } D \in \left\{ \begin{bmatrix} 0 \\ 1 \end{bmatrix}, \begin{bmatrix} 1 \\ 0 \end{bmatrix} \right\} \\[10pt]
      0 & \text{if } D \in \left\{ \begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 1 \\ 1 \end{bmatrix} \right\} \\[10pt]
      0 & \text{if } \tau_2 < \tau_1 \text{ and } D = \begin{bmatrix} 0 \\ 1 \end{bmatrix} \\[10pt]
      0 & \text{if } \tau_2 > \tau_1 \text{ and } D = \begin{bmatrix} 1 \\ 0 \end{bmatrix}
    \end{cases}
    \]
\end{frame}


\begin{frame}{Unit Assignment Probability}
    The \textbf{unit-level assignment probability} for unit \( i \) is defined as:

    \[
    p_i(X, Y(0), Y(1)) = \sum_{D : D_i = 1} \Pr(D | X, Y(0), Y(1)),
    \]

  
\end{frame}



\begin{frame}{Propensity Score}
    The \textbf{propensity score} at \( x \) is the average unit assignment probability for units with \( X_i = x \). It is defined as:

    \[
    e(x) = \frac{1}{N(x)} \sum_{i : X_i = x} p_i(X, Y(0), Y(1)),
    \]


\end{frame}

% Slide 1: Individualistic Assignment Mechanism
\begin{frame}{Individualistic Assignment Mechanism}
    \textbf{Individualistic Assignment Mechanism:} In this mechanism, the probability of each unit's treatment assignment depends only on the unit's covariates and potential outcomes, independent of the assignments of other units.
    
    \[
    \Pr(D_i | X, Y(0), Y(1)) = f(X_i, Y_i(0), Y_i(1))
    \]
    
   
\end{frame}

% Slide 2: Probabilistic Assignment Mechanism
\begin{frame}{Probabilistic Assignment Mechanism}
    \textbf{Probabilistic Assignment Mechanism:} Under this mechanism, each unit has a non-zero probability of being assigned to either treatment or control, ensuring randomness in the assignment process.
    
    \[
    0 < \Pr(D_i = 1 | X, Y(0), Y(1)) < 1 \quad \text{for all units } i
    \]
    
   
\end{frame}

% Slide 3: Unconfounded Assignment Mechanism
\begin{frame}{Unconfounded Assignment Mechanism}
    \textbf{Unconfounded Assignment Mechanism:} This mechanism assumes that assignment to treatment is independent of the potential outcomes, given the covariates. In other words, the assignment is “as good as random” conditional on covariates.
    
    \[
    \Pr(D | X, Y(0), Y(1)) = \Pr(D | X)
    \]
    
    
\end{frame}

\section{Types of Randomized Experiments}


\begin{frame}{Randomized Experiment}
    A classical randomized experiment is a randomized experiment with an assignment mechanism that is:
    
    \begin{itemize}
        \item (i) \textbf{Individualistic}: Each unit’s treatment assignment depends only on its own covariates and potential outcomes, independent of other units.
        \pause
        \item (ii) \textbf{Unconfounded}: Assignment to treatment is independent of potential outcomes given covariates, meaning assignment is “as good as random” conditional on covariates.
    \end{itemize}
\end{frame}

\begin{frame}{Bernoulli Trials}
    A \textbf{Bernoulli trial} is a classical randomized experiment where each unit is independently assigned to treatment or control, often based on a coin toss.
    
    \begin{itemize}
        \item Each unit has a probability \( q \) of being assigned to treatment and \( 1 - q \) of being assigned to control.
       \pause
        \item Each unit's assignment is independent of others, meaning the assignment for one unit does not affect the assignment for another.
        \pause 
        \item The assignment mechanism is:
            \begin{itemize}
                \item \textbf{Individualistic}: Each unit's assignment depends only on its own characteristics.
                \item \textbf{Probabilistic}: Each unit has a non-zero chance of receiving either treatment or control.
                \item \textbf{Unconfounded}: Given covariates, assignment does not depend on potential outcomes.
                \item \textbf{Controlled by the Researcher}: The probability \( q \) is specified by the researcher.
            \end{itemize}
    \end{itemize}
\end{frame}

% Bernoulli Trials: Slide 2 - Computation of Probability
\begin{frame}{Bernoulli Trials - Probability of an Assignment Vector}
    For a Bernoulli trial, the probability of an assignment vector \( D \) for \( N \) units is given by:
    
    \[
    \Pr(D | X, Y(0), Y(1)) = \prod_{i=1}^N \left( q^{D_i} \cdot (1 - q)^{1 - D_i} \right)
    \]
    
    where:
    \begin{itemize}
        \item \( D_i = 1 \) if unit \( i \) is assigned to treatment, \( D_i = 0 \) otherwise.
        \item \( q \): Probability of treatment assignment.
    \end{itemize}
    If \( q = 0.5 \), then \( \Pr(D | X, Y(0), Y(1)) = 0.5^N \).
\end{frame}


\begin{frame}{Completely Randomized Experiment - Definition}
    A \textbf{completely randomized experiment} assigns a fixed number \( N_t \) of units to treatment, and the remaining \( N - N_t \) units to control.
    
    \begin{itemize}
        \item The assignment is achieved by randomly selecting \( N_t \) units from a pool of \( N \) units.
        \item Ensures a balanced distribution of treated and control units, with exactly \( N_t \) in treatment and \( N - N_t \) in control.
        \item Each unit's assignment is \text{NOT} independent of others, but the total number of treated units is fixed by design.
        \item The assignment mechanism is:
            \begin{itemize}
                \item \textbf{Individualistic}: Each unit’s assignment depends only on its own characteristics.
                \item \textbf{Probabilistic}: Each unit has a positive probability of being selected for treatment or control.
                \item \textbf{Unconfounded}: Given covariates, assignment does not depend on potential outcomes.
                \item \textbf{Controlled by the Researcher}: The number \( N_t \) of treated units is specified by the researcher.
            \end{itemize}
    \end{itemize}
\end{frame}



% Completely Randomized Experiment: Slide 2 - Probability of an Assignment Vector
\begin{frame}{Completely Randomized Experiment - Probability of an Assignment Vector}
    In a completely randomized experiment, the probability of an assignment vector \( D \) is:
    
    \[
    \Pr(D | X, Y(0), Y(1)) = \begin{cases}
        \frac{1}{\binom{N}{N_t}} & \text{if } \sum_{i=1}^N D_i = N_t \\
        0 & \text{otherwise}
    \end{cases}
    \]
    
    where \( N_t \) is the predetermined number of units assigned to treatment.
\end{frame}

% Stratified Randomized Experiment: Slide 1 - Definition
\begin{frame}{Stratified Randomized Experiment - Definition}
    A \textbf{stratified randomized experiment} divides the population into blocks or strata based on covariates, and performs a completely randomized experiment within each block.
    
    \begin{itemize}
        \item Divides the population into strata so that units within each stratum are similar with respect to certain covariates.
        \pause
        \item Performs complete randomization within each stratum, ensuring balanced treatment and control within each block.
        \pause
        \item Reduces variability and improves the precision of causal inference estimates.
        \pause
        \item The goal is to reduce variance in the estimator and increase the power of statistical tests, enhancing the study's ability to detect treatment effects.
    \end{itemize}
\end{frame}

% Stratified Randomized Experiment: Slide 2 - Probability of an Assignment Vector
\begin{frame}{Stratified Randomized Experiment - Probability of an Assignment Vector}
    For a stratified randomized experiment with \( J \) blocks, the probability of an assignment vector \( D \) is:

    \[
    \Pr(D | X, Y(0), Y(1)) = \prod_{j=1}^J \frac{1}{\binom{N(j)}{N_t(j)}}
    \]

    where:
    \begin{itemize}
        \item \( N(j) \): Number of units in block \( j \),
        \item \( N_t(j) \): Number of treated units in block \( j \).
    \end{itemize}
\end{frame}

% Paired Randomized Experiment: Slide 1 - Definition
\begin{frame}{Paired Randomized Experiment - Definition}
    A \textbf{paired randomized experiment} is an extreme form of stratified randomization, where each block (or stratum) contains exactly two units.
    
    \begin{itemize}[<+->]
        \item Within each pair, one unit is randomly assigned to treatment and the other to control, ensuring direct comparison between similar units.
        \item Ensures close matching on covariates within each pair, which helps to control for confounding variables.
        \item Minimizes differences between treated and control units on covariates, reducing bias in the estimated treatment effect.
        \item Reduces variance in the estimator by closely aligning treatment and control units.
        \item Increases statistical power by enhancing the precision of the causal inference, making it easier to detect treatment effects.
    \end{itemize}
\end{frame}

% Paired Randomized Experiment: Slide 2 - Probability of an Assignment Vector
\begin{frame}{Paired Randomized Experiment - Probability of an Assignment Vector}
    For a paired randomized experiment with \( N/2 \) pairs, the probability of an assignment vector \( D \) is:

    \[
    \Pr(D | X, Y(0), Y(1)) = 2^{-\frac{N}{2}}
    \]

    - Each unit within a pair has an equal probability of being assigned to treatment or control.
\end{frame}

\begin{frame}{Number of Possible Values for the Assignment Vector by Design and Sample Size}
    \begin{table}[]
        \centering
        \scriptsize  % Reduce font size for the entire table
        \begin{tabular}{@{}lcccccc@{}}
            \toprule
            \shortstack{\textbf{Type of Experiment} \\ \textbf{and Design}} & \shortstack{\textbf{Number of Possible} \\ \textbf{Assignments}} & \multicolumn{4}{c}{\textbf{Number of Units (N) in Sample}} \\ 
            \cmidrule(lr){3-6}
            & & \textbf{4} & \textbf{8} & \textbf{16} & \textbf{32} \\ 
            \midrule
            \shortstack{Bernoulli \\ trial} & \( 2^N \) & 16 & 256 & 65,536 & \( 4.2 \times 10^9 \) \\[5pt]
            \shortstack{Completely \\ randomized \\ experiment} & \( \binom{N}{N/2} \) & 6 & 70 & 12,870 & \( 0.6 \times 10^9 \) \\[5pt]
            \shortstack{Stratified \\ randomized \\ experiment} & \( \binom{N/2}{N/4}^2 \) & 4 & 36 & 4,900 & \( 0.2 \times 10^9 \) \\[5pt]
            \shortstack{Paired \\ randomized \\ experiment} & \( 2^{N/2} \) & 4 & 16 & 256 & 65,536 \\ 
            \bottomrule
        \end{tabular}
    \end{table}
\end{frame}


\section{Inference  1: Fisher Exact P-Value}
\section{Inference  2: Neyman's ATE Test}
\section{Covariates and Heterogeneity}

\begin{frame}
    \frametitle{Bernoulli Trials}
\end{frame}
% Frame: Completely Randomized Experiment   
\begin{frame}
    \frametitle{Completely Randomized Experiment}
\end{frame}    

\begin{frame}
    \frametitle{Stratified Randomized Experiment}
\end{frame}   

\begin{frame}
    \frametitle{Pair Randomized Experiment}
\end{frame} 
    
\begin{frame} [allowframebreaks]
    \frametitle{References}
    \bibliographystyle{apalike}
    \bibliography{references}
\end{frame}

\end{document}


































 


